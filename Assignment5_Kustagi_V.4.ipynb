{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.  In no more than a paragraph, outline your final project. What question are you looking to answer?  What text are you using?  With whom are you working? (Note:  you will not be strictly held to this description since there are still techniques that we will cover in class. This is meant to get people thinking about how to get started more than a week before the project is due.) (5 pts.)\n",
    "\n",
    "I'm working with Paxton Butler. We are using Presidential Candidates debates to predict how they will react for the upcoming presidential candidates debates in the future. For instance, considering all the Donald Trump past debates to analyze how he reacts on particular topic and using these results to predict how he reacts in the future on certain topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#annoying bit about python: lack of native floating point division\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I'm scrapping the same text compared to the previous assignment, these are some of the comments on a seafood brand - 'Red Lobster' from Yelp.com and pedicting the sentiments using different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib import urlopen\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "pd.set_option('display.max_colwidth', 1250) #important for getting all the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Looping\n",
    "def spider(max_pages):\n",
    "    page = 0\n",
    "    html = BeautifulSoup().findAll() # initiate variable as a bs4 result set outside of while loop \n",
    "    while page <= max_pages:\n",
    "        theurl = \"http://www.yelp.com/biz/red-lobster-new-york-2?start=\" + str(page)\n",
    "        source_code = requests.get(theurl)\n",
    "        plain_text = source_code.text\n",
    "        soup = BeautifulSoup(plain_text)\n",
    "        html = html + soup.findAll(\"div\",{\"class\":\"review-content\"} )\n",
    "        page = page + 20\n",
    "    return html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to pick the data\n",
    "def toDataFrame(html):\n",
    "    DataSet = pd.DataFrame()\n",
    "    DataSet['comment'] = [comments.find('p').text for comments in html]\n",
    "    DataSet['date'] = [comments.find('span').text.replace('\\n','').replace(' ','') for comments in html]\n",
    "    return DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Pass the list to the above function to create a DataFrame\n",
    "data_frame = toDataFrame(spider(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391, 2)\n"
     ]
    }
   ],
   "source": [
    "print data_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_frame.head(10)\n",
    "data_frame.to_csv(\"final1.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ugh, you guys made me so happy tonight and don't even know it. I wanted to keep it simple tonight and went for Red Lobster in Times Square. It was also one of the restaurants close to Port Authority. If I can give anyone advice, it would be to sit at the bar, you'll get your food faster. But I also visited after hours so there was barely anyone there. Based on the receipt, my waitress was Doly? Girl, thank you! She was so sweet and kind and her partner was also. He (I didn't get his name) actually suggested the mojito for me because I had not tried it before and low and behold! It tasted exactly like my grandma's lemonade. So either they didn't make it right or my grandma has been sneaking in some good stuff and trying to get us tipsy all along. *scratches head* Either way, I loved it. The only thing I'm kinda not happy about was my $45 tab. Like. Really. I was by myself. How did I do that? Trust me when I tell you that I suck at saving and never mind the fact that food is my life.. I will spend my entire paycheck at one restaurant. Trust and believe me! Anyway, thank you Red Lobster.. For being there when I needed you the most and for taking all my money.</td>\n",
       "      <td>5/6/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I was here with my friend because we were in the area and needed to kill time before our next move. Long story short, I saw a mouse scurry across the room. I didn't want to make a big deal of it. I told the waiter. Literally nothing was done. He didn't update us saying he'd told the manager about it or ask me any additional questions at all. He just said \"okay\". Like....I am in your restaurant telling you I just saw a mouse. This was in the early evening (4 ish) and was not busy at all. He just really lacked customer service. I definitely will not be returning here.</td>\n",
       "      <td>5/19/2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  comment  \\\n",
       "0  Ugh, you guys made me so happy tonight and don't even know it. I wanted to keep it simple tonight and went for Red Lobster in Times Square. It was also one of the restaurants close to Port Authority. If I can give anyone advice, it would be to sit at the bar, you'll get your food faster. But I also visited after hours so there was barely anyone there. Based on the receipt, my waitress was Doly? Girl, thank you! She was so sweet and kind and her partner was also. He (I didn't get his name) actually suggested the mojito for me because I had not tried it before and low and behold! It tasted exactly like my grandma's lemonade. So either they didn't make it right or my grandma has been sneaking in some good stuff and trying to get us tipsy all along. *scratches head* Either way, I loved it. The only thing I'm kinda not happy about was my $45 tab. Like. Really. I was by myself. How did I do that? Trust me when I tell you that I suck at saving and never mind the fact that food is my life.. I will spend my entire paycheck at one restaurant. Trust and believe me! Anyway, thank you Red Lobster.. For being there when I needed you the most and for taking all my money.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            I was here with my friend because we were in the area and needed to kill time before our next move. Long story short, I saw a mouse scurry across the room. I didn't want to make a big deal of it. I told the waiter. Literally nothing was done. He didn't update us saying he'd told the manager about it or ask me any additional questions at all. He just said \"okay\". Like....I am in your restaurant telling you I just saw a mouse. This was in the early evening (4 ish) and was not busy at all. He just really lacked customer service. I definitely will not be returning here.   \n",
       "\n",
       "        date  \n",
       "0   5/6/2016  \n",
       "1  5/19/2016  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathname = \"C:/Anaconda2/AText Mining/Week 5/Assignment 5/\"\n",
    "filename = pathname+\"final1.csv\"\n",
    "reviewdf = pd.read_csv(filename, index_col = 0) \n",
    "print reviewdf.shape\n",
    "reviewdf.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis using Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'> 2477\n",
      "abandon => -2\n",
      "abandoned => -2\n",
      "abandons => -2\n",
      "abducted => -2\n",
      "abduction => -2\n",
      "~~~~~~~~~~~~\n",
      "yucky => -2\n",
      "yummy => 3\n",
      "zealot => -2\n",
      "zealots => -2\n",
      "zealous => 2\n"
     ]
    }
   ],
   "source": [
    "#some dictionaries assign a value - like the positivity measure in the reviews \n",
    "afinn = dict(map(lambda (k,v): (k,int(v)), [ line.split('\\t') for line in open(pathname+\"AAFINN-111.txt\") ]))\n",
    "print type(afinn), len(afinn)\n",
    "for key, value in sorted(afinn.items())[0:5]:\n",
    "    print key + \" => \" + str(value)\n",
    "print \"~~~~~~~~~~~~\"\n",
    "for key, value in sorted(afinn.items())[2472:]:\n",
    "    print key + \" => \" + str(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def afinn_sent(inputstring):\n",
    "    \n",
    "    sentcount =0\n",
    "    for word in inputstring.split():  \n",
    "        if word in afinn:\n",
    "            sentcount = sentcount + afinn[word]\n",
    "            \n",
    "    \n",
    "    if (sentcount < 0):\n",
    "        sentiment = 'Negative Comment'\n",
    "    elif (sentcount >0):\n",
    "        sentiment = 'Positive Comment'\n",
    "    else:\n",
    "        sentiment = 'Neutral Opinion'\n",
    "    \n",
    "    return sentiment\n",
    "    #return sentcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>afinn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>I went there last week, ordered the surf and turf. The steak was decent a little chewy but tasted good, the lobster was pure rubber. Not let me talk about the potatoes. To start they were cold, the first piece was fine, cold but fine. The second piece felt like a sponge, releasing water (at least I hope) as I pressed between my teethes. This made me nauseous at least by this time I was almost done with my meal.I won't come back to this place again.</td>\n",
       "      <td>Positive Comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>With family in town with a hunger for seafood at a decent price, we headed to Red Lobster in Times Square. We went for lunch on a Wednesday afternoon, around 12:30 P.M. There were a decent number of people on the upper floor where we sat, but there was no wait time. As expected, the prices were about $5-$6 more a plate than what you would expect to pay in a typical suburban Red Lobster. Our waiter was friendly enough, though it did take a decent amount of time to get our drinks. It really wasn't possible to get his attention during the meal, so we weren't able to get the infamous cheesy biscuits refilled. He came by at one point and said our order was up and he would be bring it by in just a minute. About 10 minutes later, he showed up with the food. Hmm...?As for the meal, the food was what you would expect to find in any Red Lobster. If you're a fan of fried shrimp, buttery lobster, or grilled fish, you'll probably be happy with your selection. As other reviewers have noted, they do add an automatic 18% tip to the bill. I jokingly told my dad (who picked up the tab) not to tip well, since the server was pretty MIA during the meal. He's an excellent tipper and said, \"Too bad for the waiter, he'd have received a better tip fro...</td>\n",
       "      <td>Positive Comment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               comment  \\\n",
       "310                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               I went there last week, ordered the surf and turf. The steak was decent a little chewy but tasted good, the lobster was pure rubber. Not let me talk about the potatoes. To start they were cold, the first piece was fine, cold but fine. The second piece felt like a sponge, releasing water (at least I hope) as I pressed between my teethes. This made me nauseous at least by this time I was almost done with my meal.I won't come back to this place again.   \n",
       "311  With family in town with a hunger for seafood at a decent price, we headed to Red Lobster in Times Square. We went for lunch on a Wednesday afternoon, around 12:30 P.M. There were a decent number of people on the upper floor where we sat, but there was no wait time. As expected, the prices were about $5-$6 more a plate than what you would expect to pay in a typical suburban Red Lobster. Our waiter was friendly enough, though it did take a decent amount of time to get our drinks. It really wasn't possible to get his attention during the meal, so we weren't able to get the infamous cheesy biscuits refilled. He came by at one point and said our order was up and he would be bring it by in just a minute. About 10 minutes later, he showed up with the food. Hmm...?As for the meal, the food was what you would expect to find in any Red Lobster. If you're a fan of fried shrimp, buttery lobster, or grilled fish, you'll probably be happy with your selection. As other reviewers have noted, they do add an automatic 18% tip to the bill. I jokingly told my dad (who picked up the tab) not to tip well, since the server was pretty MIA during the meal. He's an excellent tipper and said, \"Too bad for the waiter, he'd have received a better tip fro...   \n",
       "\n",
       "                afinn  \n",
       "310  Positive Comment  \n",
       "311  Positive Comment  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewdf['afinn'] = map(lambda x: afinn_sent(x), reviewdf['comment'])\n",
    "reviewdf.iloc[310:312][['comment','afinn']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T1. Create a simple bag of words (with all lowercase and no stop words) using your dataset. Identify the labels you will be trying to predict. Proceed to create a train test split of 60/40. \n",
    "Trying to predict sentiment using the bag of words by splitting data into 60:40 for testing the model. Initializing a simple vector space with No lower case and removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391, 4722)\n",
      "<type 'list'> 4722\n",
      "<type 'list'> 4722\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The</th>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lobster</th>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Red</th>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count\n",
       "The        412\n",
       "food       327\n",
       "Lobster    307\n",
       "Red        297\n",
       "good       250"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "# quick peak at unmunged feature space\n",
    "\n",
    "prelim = CountVectorizer(binary=False, lowercase = False, stop_words = 'english') \n",
    "prelim_dm = prelim.fit_transform(reviewdf['comment'])\n",
    "print prelim_dm.shape\n",
    "\n",
    "names = prelim.get_feature_names()\n",
    "print type(names), len(names)\n",
    "\n",
    "count = np.sum(prelim_dm.toarray(), axis = 0).tolist()\n",
    "print type(count), len(count)\n",
    "count_df = pd.DataFrame(count, index = names, columns = ['count'])\n",
    "\n",
    "count_df.sort_values(by=['count'], ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "['Positive Comment' 'Negative Comment' 'Positive Comment'\n",
      " 'Positive Comment' 'Positive Comment']\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "# data are X, labels are y\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X = prelim_dm.toarray()  #remember this is the output from the vectorizer\n",
    "print type(X)\n",
    "\n",
    "\n",
    "y = reviewdf['afinn'].values #this is an array of labels\n",
    "print type(y)\n",
    "\n",
    "print y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234L, 4722L)\n",
      "(157L, 4722L)\n",
      "(234L,)\n",
      "(157L,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=50) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print X_train.shape\n",
    "print X_test.shape\n",
    "print y_train.shape\n",
    "print y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Ugh, you guys made me so happy tonight and don't even know it. I wanted to keep it simple tonight and went for Red Lobster in Times Square. It was also one of the restaurants close to Port Authority. If I can give anyone advice, it would be to sit at the bar, you'll get your food faster. But I also visited after hours so there was barely anyone there. Based on the receipt, my waitress was Doly? Girl, thank you! She was so sweet and kind and her partner was also. He (I didn't get his name) actually suggested the mojito for me because I had not tried it before and low and behold! It tasted exactly like my grandma's lemonade. So either they didn't make it right or my grandma has been sneaking in some good stuff and trying to get us tipsy all along. *scratches head* Either way, I loved it. The only thing I'm kinda not happy about was my $45 tab. Like. Really. I was by myself. How did I do that? Trust me when I tell you that I suck at saving and never mind the fact that food is my life.. I will spend my entire paycheck at one restaurant. Trust and believe me! Anyway, thank you Red Lobster.. For being there when I needed you the most and for taking all my money.\n",
      "Name: comment, dtype: object\n",
      "~~~~~~~~~~~~\n",
      "0    Positive Comment\n",
      "Name: afinn, dtype: object\n",
      "~~~~~~~~~~~~~\n",
      "   00  000  00pm  06  10  100  1000  10min  10pm  11   ...    younger  youre  \\\n",
      "0   0    0     0   0   0    0     0      0     0   0   ...          0      0   \n",
      "\n",
      "   yuck  yum  yummy  zero  Époque  哈哈  在我心里依然五星  晕的找不着北  \n",
      "0     0    0      0     0       0   0         0       0  \n",
      "\n",
      "[1 rows x 4722 columns]\n"
     ]
    }
   ],
   "source": [
    "#so what are we working with?\n",
    "# We calculated sentiment indexes from the text\n",
    "print reviewdf['comment'][0:1]\n",
    "print \"~~~~~~~~~~~~\"\n",
    "print reviewdf['afinn'][0:1]\n",
    "print \"~~~~~~~~~~~~~\"\n",
    "#we created numeric representations of the text \n",
    "print pd.DataFrame(X,columns = prelim.get_feature_names())[0:1]\n",
    "\n",
    "#now we're going to use the feature space to try to predict the labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T2. Using default model parameters, fit 3 classifiers (decision tree, naïve bayes, and logistic regression) to your dataset and subsequently generate predictions (just like we did in class). Feel free to set a random state variable where appropriate to facilitate replication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref: https://www.quora.com/In-a-decision-tree-how-do-we-select-which-attribute-to-split-the-data-by-at-each-level\n",
    "Ref: https://www.quora.com/In-laymans-terms-how-does-Naive-Bayes-work\n",
    "\n",
    "### Q2. In your own words, describe the significance of the test dataset. What does the distribution of your target variable look like?  Describe what the 3 classifiers are doing differently and explain how that might affect the predictions. Which model would you expect to have the best performance? (5 pts)\n",
    "\n",
    "Test data set is created by Random Seed with 60:40 split, the above chart shows the overall distributions of sentiments. It says Positive Comments are more dominated by Negative Comments and followed by Neutral. \n",
    "\n",
    "List below are the 3 Methods used for Classification:\n",
    "\n",
    "##### A. Decision Trees:\n",
    "\n",
    "1. Compute entropy and info gain for each attribute.\n",
    "2. Sort the attributes in ascending order w.r.t. entropy (descending order for info gain)\n",
    "3. While attribute list is not empty or length (attribute list)>threshold, select the first attribute to be the root of the tree/subtree. \n",
    "4. Remove the attribute from the sorted list.\n",
    "5. Go to step 3\n",
    "\n",
    "##### B. Naive Bayes (Bayesian classifier):\n",
    "1. Assumptions: Naive model: a model that assumes that each independent variable is not affected by anything else, and that the value for the interaction between the independent and dependent variable is not related to the presence of anything else.\n",
    "\n",
    "##### C. Logistic Regression: \n",
    "1. Helps in predicting the categorical output data with the probability of the event occurring (In our case, probability of Positive Comment, Negative (or) Neutral Comment, higher the probability, the out will be classified accordingly)\n",
    "\n",
    "I would have to run, to check how these model behaves, but for these Multinomial classification I would go with Decision Trees for classification.\n",
    "\n",
    "### T1. Create a simple bag of words (with all lowercase and no stop words) using your dataset. Identify the labels you will be trying to predict. Proceed to create a train test split of 60/40. \n",
    "Trying to predict sentiment using the bag of words by splitting data into 60:40 for testing the model. Initializing a simple vector space with No lower case and removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x9534518>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAFXCAYAAACyW7XLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x951cc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get a feel for the distribution\n",
    "reviewdf['afinn'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.668789808917\n",
      "accuracy: 0.668789808917\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Negative Comment       0.28      0.55      0.37        20\n",
      "Neutral Opinion       0.30      0.14      0.19        22\n",
      "Positive Comment       0.84      0.79      0.82       115\n",
      "\n",
      "avg / total       0.70      0.67      0.67       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# fit a CART_model to the data\n",
    "DecisionTree_pre = DecisionTreeClassifier(random_state = 50)\n",
    "DecisionTree_pre.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y_test\n",
    "clf1_predicted = DecisionTree_pre.predict(X_test)\n",
    "\n",
    "\n",
    "print DecisionTree_pre.score(X_test,y_test)\n",
    "\n",
    "# summarize the fit of the CART_Model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.738853503185\n",
      "accuracy: 0.738853503185\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Negative Comment       0.33      0.10      0.15        20\n",
      "Neutral Opinion       0.00      0.00      0.00        22\n",
      "Positive Comment       0.76      0.99      0.86       115\n",
      "\n",
      "avg / total       0.60      0.74      0.65       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive_Bayes_model to the data\n",
    "NaiveBayes_pre = MultinomialNB()\n",
    "print NaiveBayes_pre\n",
    "NaiveBayes_pre.fit(X_train, y_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y_test\n",
    "clf2_predicted = NaiveBayes_pre.predict(X_test)\n",
    "\n",
    "print NaiveBayes_pre.score(X_test, y_test)\n",
    "\n",
    "# summarize the fit of the Naivebayes\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=50, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.732484076433\n",
      "accuracy: 0.732484076433\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Negative Comment       0.33      0.20      0.25        20\n",
      "Neutral Opinion       0.33      0.09      0.14        22\n",
      "Positive Comment       0.78      0.95      0.86       115\n",
      "\n",
      "avg / total       0.66      0.73      0.68       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit a logistic regression model to the data\n",
    "logit_pre = LogisticRegression(random_state = 50)\n",
    "print logit_pre\n",
    "logit_pre.fit(X_train, y_train)\n",
    "print logit_pre.score(X_test, y_test)\n",
    "\n",
    "# make predictions\n",
    "clf3_expected = y_test\n",
    "clf3_predicted = logit_pre.predict(X_test)\n",
    "\n",
    "# summarize the fit of the logit_pre_model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf3_expected, clf3_predicted)))\n",
    "print(metrics.classification_report(clf3_expected, clf3_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T3. Assess the performance of the models using any of the measures (confusion matrices, precision, recall, f1-score, and accuracy)\n",
    "By comparing the Accuracy of the different models, Naive Bayes is doing better over the other two model. In fact, Naive Bayes and Logistics Regression models have almost gives the same accurate results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3. What information is the confusion matrix conveying? What would be indicative of good performance? (5 pts)\n",
    "\n",
    "Confusion Matrix gives the details of classification and Miss Classification. The accuracy is good indicative of good indicator on performance. Below matrix should how the 3 models are performing with Accuracy Scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAADwCAYAAAAAVdH1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCDUXSSCEmvv/FvvXC6ji5ykAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcd65eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  1  8]\n",
      " [10  3  9]\n",
      " [18  6 91]]\n",
      "0.668789808917\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAAD0CAYAAACW2uOkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ng5kVcnIws0JODmZWyMnBzAr9f91gF4ne0oUjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcddd9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2   0  18]\n",
      " [  4   0  18]\n",
      " [  0   1 114]]\n",
      "0.738853503185\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQcAAADvCAYAAAD/yxH8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcd73400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4   3  13]\n",
      " [  3   2  17]\n",
      " [  5   1 109]]\n",
      "0.732484076433\n"
     ]
    }
   ],
   "source": [
    "# display confusion matrix\n",
    "def create_cm(t1, t2):\n",
    "    cm = metrics.confusion_matrix(t1, t2)\n",
    "    cm_accuracy =  metrics.accuracy_score(t1,t2)\n",
    "    plt.matshow(cm)\n",
    "    plt.title('Confusion matrix')\n",
    "    plt.colorbar()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    print(cm)\n",
    "    print  (cm_accuracy)\n",
    "\n",
    "create_cm(clf1_expected, clf1_predicted)\n",
    "create_cm(clf2_expected, clf2_predicted)\n",
    "create_cm(clf3_expected, clf3_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T4. Create a new dataframe called ‘model_performance’ with 3 columns (model_name, processing/parameters, model_accuracy) and append the name of the model, a short description of what preprocessing or parameter settings you used, and the model’s accuracy after each run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model NO</th>\n",
       "      <th>Name</th>\n",
       "      <th>Processing Parameters</th>\n",
       "      <th>Model Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 2</td>\n",
       "      <td>Prelim_Reviews_Naive Bayes</td>\n",
       "      <td>binary=False, lowercase = False, stop_words = \"english\"</td>\n",
       "      <td>0.738854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 3</td>\n",
       "      <td>Prelim_Reviews_Logistic Regression</td>\n",
       "      <td>binary=False, lowercase = False, stop_words = \"english\"</td>\n",
       "      <td>0.738854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 1</td>\n",
       "      <td>Prelim_Reviews_Decision Tree</td>\n",
       "      <td>binary=False, lowercase = False, stop_words = \"english\"</td>\n",
       "      <td>0.668790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model NO                                Name  \\\n",
       "1  Model 2          Prelim_Reviews_Naive Bayes   \n",
       "2  Model 3  Prelim_Reviews_Logistic Regression   \n",
       "0  Model 1        Prelim_Reviews_Decision Tree   \n",
       "\n",
       "                                     Processing Parameters  Model Accuracy  \n",
       "1  binary=False, lowercase = False, stop_words = \"english\"        0.738854  \n",
       "2  binary=False, lowercase = False, stop_words = \"english\"        0.738854  \n",
       "0  binary=False, lowercase = False, stop_words = \"english\"        0.668790  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =\"\"\n",
    "columns = ['Model NO', 'Name', 'Processing Parameters','Model Accuracy']\n",
    "df = pd.DataFrame(columns=columns) \n",
    "df.loc[len(df)]=['Model 1','Prelim_Reviews_Decision Tree','binary=False, lowercase = False, stop_words = \"english\"',\n",
    "                 DecisionTree_pre.score(X_test,y_test)]\n",
    "df.loc[len(df)]=['Model 2','Prelim_Reviews_Naive Bayes','binary=False, lowercase = False, stop_words = \"english\"',\n",
    "                 NaiveBayes_pre.score(X_test, y_test)]\n",
    "df.loc[len(df)]=['Model 3','Prelim_Reviews_Logistic Regression','binary=False, lowercase = False, stop_words = \"english\"',\n",
    "                 NaiveBayes_pre.score(X_test, y_test)]\n",
    "result = df.sort_values(by= 'Model Accuracy',ascending=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4. Which model performed the best? Was it the same model that you had initially suspected? (5 pts)\n",
    "Model with Naive Bayes is performing better over the other two models. Initially I thought Decision Tree could perform better in classification of multiple category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary to replace Item names, Cities, Restaurnt names etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace contractions\n",
    "import re\n",
    "\n",
    "# using dictionaries\n",
    "\n",
    "RLobster_dict = { 'chilled jumbo shrimp cocktail':'cjshrimp','parrot isle jumbo coconut shrimp':'pijcoco',\n",
    "                  'crispy shrimp lettuce wraps':'cslr', 'blueberry balsamic dressing':'bbdressing', \n",
    "                  'brown butter scampi':'bbscampi', 'cheddar bay biscuits': 'cbiscuits', 'jumbo coconut shrimp':'coco-shrimp',\n",
    "                  'bubba gump shrimp':'shrimp','red lobster':'rlob' ,\n",
    "                  'cheesy biscuits': 'cbiscuits', 'cheddar biscuits': 'cbiscuits', 'main course': 'mcourse', \n",
    "                  'endless shrimp':'eshrimp', 'coconut shrimp':'coco-shrimp', 'lobster pizza':'lpizza' , \n",
    "                  'shrimp linguini':'shrimp-linguini', 'crab linguini':'shrimp-linguini', 'shrimp scampi' : 'shrimp', \n",
    "                  'fried shrimp':'shrimp', 'shrimp alfredo':'shrimp','stuffed mushrooms':'mashroom', \n",
    "                 'shrimp cocktail':'cocktail', \n",
    "                  'caesar salad':'salad','pina colada':'pcolada','crab legs':'crab', 'new yorker': 'NYC', \n",
    "                 'ice cream':'ice-cream',  \n",
    "                  'lobster tacos':'tocos', 'lobster tails':'ltails','mozzarella sticks':'mozzsticks', \n",
    "                 'mahi tacos':'tocos',\n",
    "                  'lobster spinach dip':'lobspindip',  'jumbo fried shrimp':'jfshrimp','stuffed lobster tail':'slobtail', \n",
    "                  'sunset pina colada':'spcolada', 'shrimp alfredo pasta':'sapasta', 'crab cakes':'CC',\n",
    "                 'Crowne Plaza hotel':'cphotel',\n",
    "                 'grilled lobster':'glob', 'the ultimate feast':'Ultfest', 'meatier crab legs':'mcleg', \n",
    "                 'maine lobster tails': 'mltail', 'whipped cream':'wcream', 'Baked potato':'bakedpot', \n",
    "                 'garden salad':'gsalad', \n",
    "                 'chopped tomato':'ctomato', 'malibu hurricane':'mhurri' , 'iceberg lettuce':'icelettuce', \n",
    "                 'fried shrimp':'shrimp',\n",
    "                 'times square':'tsqr', 'times sq':'tsqr', 'new yorker':'nyc','new york':'nyc',\n",
    "                 'ruby tuesday':'rtues', 'olive garden':'oliveG', 'outback steakhouse':'obsteak', \n",
    "                 'strawberry pina colada': 'spcolada', 'endless shrimp promotion':'espromation', \n",
    "                 'lobster + sirloin combo':'lscombo'}\n",
    "\n",
    "\n",
    "def multiple_replace(dict, text): \n",
    "\n",
    "  \"\"\" Replace in 'text' all occurences of any key in the given\n",
    "  dictionary by its corresponding value.  Returns the new tring.\"\"\" \n",
    "  text = str(text).lower()\n",
    "\n",
    "  # Create a regular expression  from the dictionary keys\n",
    "  regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n",
    "\n",
    "  # For each match, look-up corresponding value in dictionary\n",
    "  return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>date</th>\n",
       "      <th>afinn</th>\n",
       "      <th>cleantext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>We had booked table half day in advance but were placed in an freezing cold  corner. We refused to give tips, which made waiter very irritating. Sad sad, since lobster and shrimps were fresh and well prepared.</td>\n",
       "      <td>7/5/2016</td>\n",
       "      <td>Negative Comment</td>\n",
       "      <td>we had booked table half day in advance but were placed in an freezing cold  corner. we refused to give tips, which made waiter very irritating. sad sad, since lobster and shrimps were fresh and well prepared.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                             comment  \\\n",
       "7  We had booked table half day in advance but were placed in an freezing cold  corner. We refused to give tips, which made waiter very irritating. Sad sad, since lobster and shrimps were fresh and well prepared.   \n",
       "\n",
       "       date             afinn  \\\n",
       "7  7/5/2016  Negative Comment   \n",
       "\n",
       "                                                                                                                                                                                                           cleantext  \n",
       "7  we had booked table half day in advance but were placed in an freezing cold  corner. we refused to give tips, which made waiter very irritating. sad sad, since lobster and shrimps were fresh and well prepared.  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewdf['cleantext'] = map(lambda x: multiple_replace(RLobster_dict, x), reviewdf['comment'])\n",
    "reviewdf[7:8] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customizing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'frozenset'>\n",
      "318\n",
      "frozenset(['all', 'six', 'less', 'being', 'indeed', 'over', 'move', 'anyway', 'four', 'not', 'own', 'through', 'yourselves', 'fify', 'where', 'mill', 'only', 'find', 'before', 'one', 'whose', 'system', 'how', 'somewhere', 'with', 'thick', 'show', 'had', 'enough', 'should', 'to', 'must', 'whom', 'seeming', 'under', 'ours', 'has', 'might', 'thereafter', 'latterly', 'do', 'them', 'his', 'around', 'than', 'get', 'very', 'de', 'none', 'cannot', 'every', 'whether', 'they', 'front', 'during', 'thus', 'now', 'him', 'nor', 'name', 'several', 'hereafter', 'always', 'who', 'cry', 'whither', 'this', 'someone', 'either', 'each', 'become', 'thereupon', 'sometime', 'side', 'two', 'therein', 'twelve', 'because', 'often', 'ten', 'our', 'eg', 'some', 'back', 'up', 'go', 'namely', 'towards', 'are', 'further', 'beyond', 'ourselves', 'yet', 'out', 'even', 'will', 'what', 'still', 'for', 'bottom', 'mine', 'since', 'please', 'forty', 'per', 'its', 'everything', 'behind', 'un', 'above', 'between', 'it', 'neither', 'seemed', 'ever', 'across', 'she', 'somehow', 'be', 'we', 'full', 'never', 'sixty', 'however', 'here', 'otherwise', 'were', 'whereupon', 'nowhere', 'although', 'found', 'alone', 're', 'along', 'fifteen', 'by', 'both', 'about', 'last', 'would', 'anything', 'via', 'many', 'could', 'thence', 'put', 'against', 'keep', 'etc', 'amount', 'became', 'ltd', 'hence', 'onto', 'or', 'con', 'among', 'already', 'co', 'afterwards', 'formerly', 'within', 'seems', 'into', 'others', 'while', 'whatever', 'except', 'down', 'hers', 'everyone', 'done', 'least', 'another', 'whoever', 'moreover', 'couldnt', 'throughout', 'anyhow', 'yourself', 'three', 'from', 'her', 'few', 'together', 'top', 'there', 'due', 'been', 'next', 'anyone', 'eleven', 'much', 'call', 'therefore', 'interest', 'then', 'thru', 'themselves', 'hundred', 'was', 'sincere', 'empty', 'more', 'himself', 'elsewhere', 'mostly', 'on', 'fire', 'am', 'becoming', 'hereby', 'amongst', 'else', 'part', 'everywhere', 'too', 'herself', 'former', 'those', 'he', 'me', 'myself', 'made', 'twenty', 'these', 'bill', 'cant', 'us', 'until', 'besides', 'nevertheless', 'below', 'anywhere', 'nine', 'can', 'of', 'toward', 'my', 'something', 'and', 'whereafter', 'whenever', 'give', 'almost', 'wherever', 'is', 'describe', 'beforehand', 'herein', 'an', 'as', 'itself', 'at', 'have', 'in', 'seem', 'whence', 'ie', 'any', 'fill', 'again', 'hasnt', 'inc', 'thereby', 'thin', 'no', 'perhaps', 'latter', 'meanwhile', 'when', 'detail', 'same', 'wherein', 'beside', 'also', 'that', 'other', 'take', 'which', 'becomes', 'you', 'if', 'nobody', 'see', 'though', 'may', 'after', 'upon', 'most', 'hereupon', 'eight', 'but', 'serious', 'nothing', 'such', 'your', 'why', 'a', 'off', 'whereby', 'third', 'i', 'whole', 'noone', 'sometimes', 'well', 'amoungst', 'yours', 'their', 'rather', 'without', 'so', 'five', 'the', 'first', 'whereas', 'once'])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text \n",
    "\n",
    "skl_stopwords = text.ENGLISH_STOP_WORDS\n",
    "print type(skl_stopwords)\n",
    "print len(skl_stopwords)\n",
    "print(skl_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318\n",
      "314\n"
     ]
    }
   ],
   "source": [
    "#(['cannot', 'never', 'won', 'shouldn', 'couldn', 'mightn', 'couldn', 'don'])\n",
    "b = set(skl_stopwords)\n",
    "\n",
    "# sets can be more forgiving than lists\n",
    "print len(b)\n",
    "keepwords = set(['cannot', 'never', 'won', 'shouldn', 'couldn', 'mightn', 'couldn','before','after'])\n",
    "my_stopwords = b - keepwords\n",
    "print len(my_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'dict'> 2477\n",
      "abandon => -2\n",
      "abandoned => -2\n",
      "abandons => -2\n",
      "abducted => -2\n",
      "abduction => -2\n",
      "~~~~~~~~~~~~\n",
      "yucky => -2\n",
      "yummy => 3\n",
      "zealot => -2\n",
      "zealots => -2\n",
      "zealous => 2\n"
     ]
    }
   ],
   "source": [
    "#some dictionaries assign a value - like the positivity measure in the reviews \n",
    "afinn = dict(map(lambda (k,v): (k,int(v)), [ line.split('\\t') for line in open(pathname+\"AAFINN-111.txt\") ]))\n",
    "print type(afinn), len(afinn)\n",
    "for key, value in sorted(afinn.items())[0:5]:\n",
    "    print key + \" => \" + str(value)\n",
    "print \"~~~~~~~~~~~~\"\n",
    "for key, value in sorted(afinn.items())[2472:]:\n",
    "    print key + \" => \" + str(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def afinn_sent(inputstring):\n",
    "    \n",
    "    sentcount =0\n",
    "    for word in inputstring.split():  \n",
    "        if word in afinn:\n",
    "            sentcount = sentcount + afinn[word]\n",
    "            \n",
    "    \n",
    "    if (sentcount < 0):\n",
    "        sentiment = 'Negative Comment'\n",
    "    elif (sentcount >0):\n",
    "        sentiment = 'Positive Comment'\n",
    "    else:\n",
    "        sentiment = 'Neutral Opinion'\n",
    "    \n",
    "    return sentiment\n",
    "    #return sentcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>afinn</th>\n",
       "      <th>afinn1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>I went there last week, ordered the surf and turf. The steak was decent a little chewy but tasted good, the lobster was pure rubber. Not let me talk about the potatoes. To start they were cold, the first piece was fine, cold but fine. The second piece felt like a sponge, releasing water (at least I hope) as I pressed between my teethes. This made me nauseous at least by this time I was almost done with my meal.I won't come back to this place again.</td>\n",
       "      <td>Positive Comment</td>\n",
       "      <td>Positive Comment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>With family in town with a hunger for seafood at a decent price, we headed to Red Lobster in Times Square. We went for lunch on a Wednesday afternoon, around 12:30 P.M. There were a decent number of people on the upper floor where we sat, but there was no wait time. As expected, the prices were about $5-$6 more a plate than what you would expect to pay in a typical suburban Red Lobster. Our waiter was friendly enough, though it did take a decent amount of time to get our drinks. It really wasn't possible to get his attention during the meal, so we weren't able to get the infamous cheesy biscuits refilled. He came by at one point and said our order was up and he would be bring it by in just a minute. About 10 minutes later, he showed up with the food. Hmm...?As for the meal, the food was what you would expect to find in any Red Lobster. If you're a fan of fried shrimp, buttery lobster, or grilled fish, you'll probably be happy with your selection. As other reviewers have noted, they do add an automatic 18% tip to the bill. I jokingly told my dad (who picked up the tab) not to tip well, since the server was pretty MIA during the meal. He's an excellent tipper and said, \"Too bad for the waiter, he'd have received a better tip fro...</td>\n",
       "      <td>Positive Comment</td>\n",
       "      <td>Positive Comment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               comment  \\\n",
       "310                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               I went there last week, ordered the surf and turf. The steak was decent a little chewy but tasted good, the lobster was pure rubber. Not let me talk about the potatoes. To start they were cold, the first piece was fine, cold but fine. The second piece felt like a sponge, releasing water (at least I hope) as I pressed between my teethes. This made me nauseous at least by this time I was almost done with my meal.I won't come back to this place again.   \n",
       "311  With family in town with a hunger for seafood at a decent price, we headed to Red Lobster in Times Square. We went for lunch on a Wednesday afternoon, around 12:30 P.M. There were a decent number of people on the upper floor where we sat, but there was no wait time. As expected, the prices were about $5-$6 more a plate than what you would expect to pay in a typical suburban Red Lobster. Our waiter was friendly enough, though it did take a decent amount of time to get our drinks. It really wasn't possible to get his attention during the meal, so we weren't able to get the infamous cheesy biscuits refilled. He came by at one point and said our order was up and he would be bring it by in just a minute. About 10 minutes later, he showed up with the food. Hmm...?As for the meal, the food was what you would expect to find in any Red Lobster. If you're a fan of fried shrimp, buttery lobster, or grilled fish, you'll probably be happy with your selection. As other reviewers have noted, they do add an automatic 18% tip to the bill. I jokingly told my dad (who picked up the tab) not to tip well, since the server was pretty MIA during the meal. He's an excellent tipper and said, \"Too bad for the waiter, he'd have received a better tip fro...   \n",
       "\n",
       "                afinn            afinn1  \n",
       "310  Positive Comment  Positive Comment  \n",
       "311  Positive Comment  Positive Comment  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewdf['afinn1'] = map(lambda x: afinn_sent(x), reviewdf['cleantext'])\n",
    "reviewdf.iloc[310:312][['comment','afinn','afinn1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afinn</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative Comment</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral Opinion</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Comment</th>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0             count\n",
       "afinn                  \n",
       "Negative Comment     62\n",
       "Neutral Opinion      45\n",
       "Positive Comment    284"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tab = pd.crosstab(index=reviewdf['afinn'],  # Make a crosstab\n",
    "                              columns=\"count\")      # Name the count column\n",
    "\n",
    "my_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>afinn1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative Comment</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral Opinion</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Comment</th>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0             count\n",
       "afinn1                 \n",
       "Negative Comment     63\n",
       "Neutral Opinion      37\n",
       "Positive Comment    291"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tab1 = pd.crosstab(index=reviewdf['afinn1'],  # Make a crosstab\n",
    "                              columns=\"count\")      # Name the count column\n",
    "\n",
    "my_tab1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391, 3151)\n",
      "(391, 3151)\n",
      "<type 'list'> 3151\n",
      "<type 'list'> 3151\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rlob</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrimp</th>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "food      350\n",
       "rlob      327\n",
       "good      270\n",
       "shrimp    239\n",
       "time      191"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# instantiate vectorizer(s)\n",
    "cv1 = CountVectorizer(lowercase=True, \n",
    "                     stop_words=my_stopwords,\n",
    "                     binary=False,\n",
    "                     max_df=0.95, \n",
    "                     min_df=0.003,\n",
    "                     ngram_range = (1,2)) \n",
    "tfidf1 = TfidfVectorizer(lowercase=True, \n",
    "                        stop_words= my_stopwords, \n",
    "                        max_df=0.95, \n",
    "                        min_df=0.003,\n",
    "                        ngram_range = (1,2)) \n",
    "\n",
    "# fit and transform text\n",
    "cv_dm = cv1.fit_transform(reviewdf['cleantext'])\n",
    "tfidf_dm = tfidf1.fit_transform(reviewdf['cleantext'])\n",
    "\n",
    "# print matrix shape(s)\n",
    "print cv_dm.shape\n",
    "print tfidf_dm.shape\n",
    "names = cv1.get_feature_names()\n",
    "print type(names), len(names)\n",
    "\n",
    "count = np.sum(cv_dm.toarray(), axis = 0).tolist()\n",
    "print type(count), len(count)\n",
    "count_df = pd.DataFrame(count, index = names, columns = ['count'])\n",
    "\n",
    "count_df.sort_values(by= ['count'], ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "['Positive Comment' 'Negative Comment' 'Positive Comment'\n",
      " 'Positive Comment' 'Positive Comment']\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "# data are X, labels are y\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X1 = cv_dm.toarray()  #remember this is the output from the vectorizer\n",
    "print type(X)\n",
    "\n",
    "\n",
    "y1 = reviewdf['afinn1'].values #this is an array of labels\n",
    "print type(y1)\n",
    "\n",
    "print y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234L, 3151L)\n",
      "(157L, 3151L)\n",
      "(234L,)\n",
      "(157L,)\n"
     ]
    }
   ],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.4, random_state=50) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print X1_train.shape\n",
    "print X1_test.shape\n",
    "print y1_train.shape\n",
    "print y1_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.  Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.656050955414\n",
      "accuracy: 0.668789808917\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Negative Comment       0.28      0.55      0.37        20\n",
      "Neutral Opinion       0.30      0.14      0.19        22\n",
      "Positive Comment       0.84      0.79      0.82       115\n",
      "\n",
      "avg / total       0.70      0.67      0.67       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# fit a CART_model to the data\n",
    "DecisionTree_clean = DecisionTreeClassifier(random_state = 50)\n",
    "DecisionTree_clean.fit(X1_train, y1_train)\n",
    "\n",
    "# make predictions\n",
    "#clf1_expected = y1_test\n",
    "#clf1_predicted = DecisionTree_clean.predict(X1_test)\n",
    "\n",
    "\n",
    "print DecisionTree_clean.score(X1_test,y1_test)\n",
    "\n",
    "# summarize the fit of the CART_Model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.777070063694\n",
      "accuracy: 0.777070063694\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Negative Comment       0.50      0.33      0.40        21\n",
      "Neutral Opinion       0.00      0.00      0.00        15\n",
      "Positive Comment       0.81      0.95      0.87       121\n",
      "\n",
      "avg / total       0.69      0.78      0.73       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive_Bayes_model to the data\n",
    "NaiveBayes_clean = MultinomialNB()\n",
    "print NaiveBayes_clean\n",
    "NaiveBayes_clean.fit(X1_train, y1_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y1_test\n",
    "clf2_predicted = NaiveBayes_clean.predict(X1_test)\n",
    "\n",
    "print NaiveBayes_clean.score(X1_test, y1_test)\n",
    "\n",
    "# summarize the fit of the Naivebayes\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=50, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.764331210191\n",
      "accuracy: 0.764331210191\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Negative Comment       0.40      0.29      0.33        21\n",
      "Neutral Opinion       0.50      0.13      0.21        15\n",
      "Positive Comment       0.81      0.93      0.86       121\n",
      "\n",
      "avg / total       0.73      0.76      0.73       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit a logistic regression model to the data\n",
    "logit_clean = LogisticRegression(random_state = 50)\n",
    "print logit_clean\n",
    "logit_clean.fit(X1_train, y1_train)\n",
    "print logit_clean.score(X1_test, y1_test)\n",
    "\n",
    "# make predictions\n",
    "clf3_expected = y1_test\n",
    "clf3_predicted = logit_clean.predict(X1_test)\n",
    "\n",
    "# summarize the fit of the logit_pre_model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf3_expected, clf3_predicted)))\n",
    "print(metrics.classification_report(clf3_expected, clf3_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "['Positive Comment' 'Negative Comment' 'Positive Comment'\n",
      " 'Positive Comment' 'Positive Comment']\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "# data are X, labels are y\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X2 = tfidf_dm.toarray()  #remember this is the output from the vectorizer\n",
    "print type(X)\n",
    "\n",
    "\n",
    "y2 = reviewdf['afinn1'].values #this is an array of labels\n",
    "print type(y)\n",
    "\n",
    "print y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234L, 3151L)\n",
      "(157L, 3151L)\n",
      "(234L,)\n",
      "(157L,)\n"
     ]
    }
   ],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.4, random_state=50) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print X2_train.shape\n",
    "print X2_test.shape\n",
    "print y2_train.shape\n",
    "print y2_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.617834394904\n",
      "accuracy: 0.617834394904\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Negative Comment       0.20      0.24      0.22        21\n",
      "Neutral Opinion       0.17      0.33      0.23        15\n",
      "Positive Comment       0.84      0.72      0.78       121\n",
      "\n",
      "avg / total       0.69      0.62      0.65       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# fit a CART_model to the data\n",
    "DecisionTree_Tfidf = DecisionTreeClassifier(random_state = 50)\n",
    "DecisionTree_Tfidf.fit(X2_train, y2_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y2_test\n",
    "clf1_predicted = DecisionTree_Tfidf.predict(X2_test)\n",
    "\n",
    "\n",
    "print DecisionTree_Tfidf.score(X2_test,y2_test)\n",
    "\n",
    "# summarize the fit of the CART_Model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.770700636943\n",
      "accuracy: 0.770700636943\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Negative Comment       0.00      0.00      0.00        21\n",
      "Neutral Opinion       0.00      0.00      0.00        15\n",
      "Positive Comment       0.77      1.00      0.87       121\n",
      "\n",
      "avg / total       0.59      0.77      0.67       157\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive_Bayes_model to the data\n",
    "NaiveBayes_Tfidf = MultinomialNB()\n",
    "print NaiveBayes_Tfidf\n",
    "NaiveBayes_Tfidf.fit(X2_train, y2_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y2_test\n",
    "clf2_predicted = NaiveBayes_Tfidf.predict(X2_test)\n",
    "\n",
    "print NaiveBayes_Tfidf.score(X2_test, y2_test)\n",
    "\n",
    "# summarize the fit of the Naivebayes\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=50, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.770700636943\n",
      "accuracy: 0.770700636943\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Negative Comment       0.00      0.00      0.00        21\n",
      "Neutral Opinion       0.00      0.00      0.00        15\n",
      "Positive Comment       0.77      1.00      0.87       121\n",
      "\n",
      "avg / total       0.59      0.77      0.67       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit a logistic regression model to the data\n",
    "logit_Tfidf = LogisticRegression(random_state = 50)\n",
    "print logit_Tfidf\n",
    "logit_Tfidf.fit(X2_train, y2_train)\n",
    "print logit_Tfidf.score(X2_test, y2_test)\n",
    "\n",
    "# make predictions\n",
    "clf3_expected = y2_test\n",
    "clf3_predicted = logit_Tfidf.predict(X2_test)\n",
    "\n",
    "# summarize the fit of the logit_pre_model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf3_expected, clf3_predicted)))\n",
    "print(metrics.classification_report(clf3_expected, clf3_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### T5. Using various vector space models with various vectorizer parameters, repeat tasks 2, 3, and 4 to track the improving/worsening performance of your model(s). Perform at least 2 more iterations (of 3 models) so you should end up with at least 9 rows in your ‘model performance’ data frame.\n",
    "\n",
    "### Q5. Which model ultimately performed the best? Why? What else could you do to continually improve the model’s performance? (15 pts)\n",
    "Naive Bayes with Count Vectorizer, for clean text is doing the best compared to other models.\n",
    "The model could able to predict the text data set with 77% accurately. The Vector space is created using the clean text - after replacing Red Lobster specific words using RL dictionary. \n",
    "\n",
    "Considering the sentiment of word, preceding to the sentiment word from the corpus could make difference. A special customized dictionary for RL to be created in the further steps to see how it could help in predicting the text case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model NO</th>\n",
       "      <th>Name</th>\n",
       "      <th>Processing Parameters</th>\n",
       "      <th>Model Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model 5</td>\n",
       "      <td>CleanText_CV_Naive Bayes</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.777070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Model 8</td>\n",
       "      <td>CleanText_TfIdf_Naive Bayes</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.770701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Model 9</td>\n",
       "      <td>CleanText_TfIdf_Logistic Regression</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.770701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Model 6</td>\n",
       "      <td>CleanText_CV_Logistic Regression</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.764331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 2</td>\n",
       "      <td>Prelim_Reviews_Naive Bayes</td>\n",
       "      <td>binary=False, lowercase = False, stop_words = \"english\"</td>\n",
       "      <td>0.738854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 3</td>\n",
       "      <td>Prelim_Reviews_Logistic Regression</td>\n",
       "      <td>binary=False, lowercase = False, stop_words = \"english\"</td>\n",
       "      <td>0.738854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 1</td>\n",
       "      <td>Prelim_Reviews_Decision Tree</td>\n",
       "      <td>binary=False, lowercase = False, stop_words = \"english\"</td>\n",
       "      <td>0.668790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 4</td>\n",
       "      <td>CleanText_CV_Decision Tree</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.656051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Model 7</td>\n",
       "      <td>CleanText_TfIdf_Decision Tree</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.617834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model NO                                 Name  \\\n",
       "4  Model 5             CleanText_CV_Naive Bayes   \n",
       "7  Model 8          CleanText_TfIdf_Naive Bayes   \n",
       "8  Model 9  CleanText_TfIdf_Logistic Regression   \n",
       "5  Model 6     CleanText_CV_Logistic Regression   \n",
       "1  Model 2           Prelim_Reviews_Naive Bayes   \n",
       "2  Model 3   Prelim_Reviews_Logistic Regression   \n",
       "0  Model 1         Prelim_Reviews_Decision Tree   \n",
       "3  Model 4           CleanText_CV_Decision Tree   \n",
       "6  Model 7        CleanText_TfIdf_Decision Tree   \n",
       "\n",
       "                                                                                   Processing Parameters  \\\n",
       "4  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "7  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "8  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "5  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "1                                                binary=False, lowercase = False, stop_words = \"english\"   \n",
       "2                                                binary=False, lowercase = False, stop_words = \"english\"   \n",
       "0                                                binary=False, lowercase = False, stop_words = \"english\"   \n",
       "3  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "6  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "\n",
       "   Model Accuracy  \n",
       "4        0.777070  \n",
       "7        0.770701  \n",
       "8        0.770701  \n",
       "5        0.764331  \n",
       "1        0.738854  \n",
       "2        0.738854  \n",
       "0        0.668790  \n",
       "3        0.656051  \n",
       "6        0.617834  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[len(df)]=['Model 4','CleanText_CV_Decision Tree',\n",
    "                 'lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)',\n",
    "                 DecisionTree_clean.score(X1_test,y1_test)]\n",
    "df.loc[len(df)]=['Model 5','CleanText_CV_Naive Bayes',\n",
    "                 'lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)',\n",
    "                 NaiveBayes_clean.score(X1_test,y1_test)]\n",
    "df.loc[len(df)]=['Model 6','CleanText_CV_Logistic Regression',\n",
    "                 'lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)',\n",
    "                 logit_clean.score(X1_test, y1_test)]\n",
    "df.loc[len(df)]=['Model 7','CleanText_TfIdf_Decision Tree',\n",
    "                 'lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)',\n",
    "                 DecisionTree_Tfidf.score(X2_test,y2_test)]\n",
    "df.loc[len(df)]=['Model 8','CleanText_TfIdf_Naive Bayes',\n",
    "                 'lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)',\n",
    "                 NaiveBayes_Tfidf.score(X2_test, y2_test)]\n",
    "df.loc[len(df)]=['Model 9','CleanText_TfIdf_Logistic Regression',\n",
    "                 'lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)',\n",
    "                 logit_Tfidf.score(X2_test, y2_test)]\n",
    "result = df.sort_values(by= 'Model Accuracy',ascending=False)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T6. Choose one preprocessing option (stemming, lemmatization, custom dictionary, custom stop words, etc.) and recreate your feature space.  Repeat the predictions exercise with the best 3 models and add the results to your data frame for a total of 12 rows. (Don’t forget to recreate the test/train split on the new feature space.)\n",
    "\n",
    "Considered Count Vectorizer instead of Tfidf in the further step, as it was more reliable in predicting all 3 outcomes (Positive, Negative and Neutral Comments)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. How did the preprocessing affect the feature space? Why did you choose that option?  What changed (not just size)?\n",
    "\n",
    "Used lemmatizer for preprocessing the text and creating the new feature space. Features has increase from 3151 to 3333 Features. Reason because before creating Count Vectorizer and removing English word, I have applied the lemmatize, which chopped all the 'S' in the end leaving 'Was'  as 'Wa' behind after initiating the vector space, Simultaneously my feature space has increased, with decrease in the accuracy in predicting the test case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Applied the lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lets try some basic stemming\n",
    "stemlist = []\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer() #define method (http://www.nltk.org/api/nltk.stem.html#nltk.stem.porter.PorterStemmer)\n",
    "reviewdf['cleantext'] = map(lambda x: x.decode('latin-1').encode('ascii','ignore'), reviewdf['cleantext'])\n",
    "\n",
    "for row in reviewdf['cleantext']:\n",
    "    text = row.split() #splits the text into a list of pieces\n",
    "    stemtext = [wnl.lemmatize(word) for word in text] #stems each word individually\n",
    "    stem2text = [' '.join(stemtext)] #picks out all the text and sticks it together with spaces\n",
    "    stemlist += stem2text #creates a list of stemmed strings\n",
    "\n",
    "\n",
    "reviewdf['lemtext'] = stemlist #creates a new column out of stemmed text \n",
    "reviewdf.to_csv(\"final2.csv\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HL pos  size: 2006\n",
      "['a+', 'abound', 'abounds', 'abundance', 'abundant', 'accessable', 'accessible', 'acclaim', 'acclaimed', 'acclamation']\n",
      "HL neg  size: 4783\n",
      "['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable', 'abominably', 'abominate', 'abomination', 'abort', 'aborted']\n"
     ]
    }
   ],
   "source": [
    "#some sort into buckets\n",
    "HLpos = [line.strip() for line in  open(pathname+'\\HHLpos.txt','r')]\n",
    "HLneg = [line.strip() for line in  open(pathname +'\\HHLneg.txt','r')]\n",
    "print \"HL pos  size: \" + str(len(HLpos))\n",
    "print HLpos[0:10]\n",
    "print \"HL neg  size: \" + str(len(HLneg))\n",
    "print HLneg[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hl_sent(inputstring):\n",
    "\n",
    "    poscount = 0\n",
    "    negcount = 0\n",
    "    \n",
    "    for word in inputstring.split(): \n",
    "        if HLpos.count(word):\n",
    "            poscount +=1\n",
    "        elif HLneg.count(word):\n",
    "            negcount +=1\n",
    "     \n",
    "    \n",
    "    if poscount+negcount > 0:\n",
    "        t = float((poscount - negcount)/(poscount+negcount))    \n",
    "    else:\n",
    "        t = 0\n",
    "    \n",
    "    \n",
    "    if t > 0:\n",
    "        tone = \"Positive Review\"\n",
    "    elif t < 0:\n",
    "        tone = \"Negative Review\"\n",
    "    else:\n",
    "        tone = \"Neutral tone\"\n",
    "    \n",
    "    return tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:9: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal\n"
     ]
    }
   ],
   "source": [
    "reviewdf['hlsent'] = map(lambda x: hl_sent(x), reviewdf['lemtext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hlsent</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative Review</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral tone</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Review</th>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0            count\n",
       "hlsent                \n",
       "Negative Review     63\n",
       "Neutral tone        54\n",
       "Positive Review    274"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tab = pd.crosstab(index=reviewdf['hlsent'],  # Make a crosstab\n",
    "                              columns=\"count\")      # Name the count column\n",
    "\n",
    "my_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391, 3333)\n",
      "(391, 3333)\n",
      "<type 'list'> 3333\n",
      "<type 'list'> 3333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wa</th>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rlob</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrimp</th>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "wa        940\n",
       "food      353\n",
       "rlob      327\n",
       "good      270\n",
       "shrimp    258"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_dm = cv1.fit_transform(reviewdf['lemtext'])\n",
    "tfidf_dm = tfidf1.fit_transform(reviewdf['lemtext'])\n",
    "# print matrix shape(s)\n",
    "print cv_dm.shape\n",
    "print tfidf_dm.shape\n",
    "names = cv1.get_feature_names()\n",
    "print type(names), len(names)\n",
    "\n",
    "count = np.sum(cv_dm.toarray(), axis = 0).tolist()\n",
    "print type(count), len(count)\n",
    "count_df = pd.DataFrame(count, index = names, columns = ['count'])\n",
    "\n",
    "count_df.sort_values(by= ['count'], ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391, 3333)\n",
      "<type 'list'> 3333\n",
      "<type 'list'> 3333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wa</th>\n",
       "      <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rlob</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrimp</th>\n",
       "      <td>258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "wa        940\n",
       "food      353\n",
       "rlob      327\n",
       "good      270\n",
       "shrimp    258"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2 = CountVectorizer(lowercase=True, \n",
    "                     stop_words=my_stopwords,\n",
    "                     binary=False,\n",
    "                     max_df=0.95, \n",
    "                     min_df=0.003,\n",
    "                     ngram_range = (1,2)) \n",
    "\n",
    "# fit and transform text\n",
    "cv2_dm = cv2.fit_transform(reviewdf['lemtext'])\n",
    "\n",
    "# print matrix shape(s)\n",
    "print cv2_dm.shape\n",
    "names = cv2.get_feature_names()\n",
    "print type(names), len(names)\n",
    "\n",
    "count = np.sum(cv2_dm.toarray(), axis = 0).tolist()\n",
    "print type(count), len(count)\n",
    "count_df = pd.DataFrame(count, index = names, columns = ['count'])\n",
    "\n",
    "count_df.sort_values(by= ['count'], ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "['Positive Review' 'Negative Review' 'Positive Review' 'Positive Review'\n",
      " 'Positive Review' 'Positive Review' 'Positive Review' 'Negative Review'\n",
      " 'Positive Review' 'Positive Review']\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "# data are X, labels are y\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X3 = cv2_dm.toarray()  #remember this is the output from the vectorizer\n",
    "print type(X3)\n",
    "\n",
    "\n",
    "y3 = reviewdf['hlsent'].values #this is an array of labels\n",
    "print type(y3)\n",
    "\n",
    "print y3[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234L, 3333L)\n",
      "(157L, 3333L)\n",
      "(234L,)\n",
      "(157L,)\n"
     ]
    }
   ],
   "source": [
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.4, random_state=50) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print X3_train.shape\n",
    "print X3_test.shape\n",
    "print y3_train.shape\n",
    "print y3_test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Q7. How did the preprocessing affect the performance of the models? Is this the result you would have expected? \n",
    "\n",
    "The preprocessing with Lemmentizer did not help in increasing the accuracy of the model. Maybe because the stop words were not removed before the lemmentization. Which lead to the increase in the feature space, but also decreases the accuracy of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8. Are you satisfied with the performance of any of the models?  Why or Why not?  What else might you investigate? (15 pts)\n",
    "\n",
    "Yes, Im very much satisfied with the 5th Model & 6th Model, Models with Naive Bayes and Logistic Regress methodology to determine the Output. Because these models have high accuracy of around 77%. Parameter used in there models \"lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)\" ; Very importantly the Min and Max_df ranges are playing majore role in the predicting the outcome.\n",
    "\n",
    "It might be very interesting to see how the result improve, if we considere the sentiment of previous word from the corpus. Im planning to build a cutomized 'negate' and 'amplify' dictionary with all sentiment pair from the corpus in my further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.541401273885\n",
      "accuracy: 0.541401273885\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.12      0.26      0.16        19\n",
      "Neutral tone       0.22      0.07      0.11        29\n",
      "Positive Review       0.74      0.72      0.73       109\n",
      "\n",
      "avg / total       0.57      0.54      0.54       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# fit a CART_model to the data\n",
    "DecisionTree_Stem_cv = DecisionTreeClassifier(random_state = 50)\n",
    "DecisionTree_Stem_cv.fit(X3_train, y3_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y3_test\n",
    "clf1_predicted = DecisionTree_Stem_cv.predict(X3_test)\n",
    "\n",
    "\n",
    "print DecisionTree_Stem_cv.score(X3_test,y3_test)\n",
    "\n",
    "# summarize the fit of the CART_Model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.687898089172\n",
      "accuracy: 0.687898089172\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.40      0.21      0.28        19\n",
      "Neutral tone       0.00      0.00      0.00        29\n",
      "Positive Review       0.71      0.95      0.81       109\n",
      "\n",
      "avg / total       0.54      0.69      0.60       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive_Bayes_model to the data\n",
    "NaiveBayes_Stem_cv = MultinomialNB()\n",
    "print NaiveBayes_Stem_cv\n",
    "NaiveBayes_Stem_cv.fit(X3_train, y3_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y3_test\n",
    "clf2_predicted = NaiveBayes_Stem_cv.predict(X3_test)\n",
    "\n",
    "print NaiveBayes_Stem_cv.score(X3_test, y3_test)\n",
    "\n",
    "# summarize the fit of the Naivebayes\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=50, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.68152866242\n",
      "accuracy: 0.68152866242\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "Negative Review       0.27      0.21      0.24        19\n",
      "Neutral tone       0.33      0.07      0.11        29\n",
      "Positive Review       0.74      0.93      0.82       109\n",
      "\n",
      "avg / total       0.61      0.68      0.62       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit a logistic regression model to the data\n",
    "logit_Stem_cv = LogisticRegression(random_state = 50)\n",
    "print logit_Stem_cv\n",
    "logit_Stem_cv.fit(X3_train, y3_train)\n",
    "print logit_Stem_cv.score(X3_test, y3_test)\n",
    "\n",
    "# make predictions\n",
    "clf3_expected = y3_test\n",
    "clf3_predicted = logit_Stem_cv.predict(X3_test)\n",
    "\n",
    "# summarize the fit of the logit_pre_model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf3_expected, clf3_predicted)))\n",
    "print(metrics.classification_report(clf3_expected, clf3_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model NO</th>\n",
       "      <th>Name</th>\n",
       "      <th>Processing Parameters</th>\n",
       "      <th>Model Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model 5</td>\n",
       "      <td>CleanText_CV_Naive Bayes</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.777070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Model 8</td>\n",
       "      <td>CleanText_TfIdf_Naive Bayes</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.770701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Model 9</td>\n",
       "      <td>CleanText_TfIdf_Logistic Regression</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.770701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Model 6</td>\n",
       "      <td>CleanText_CV_Logistic Regression</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.764331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 2</td>\n",
       "      <td>Prelim_Reviews_Naive Bayes</td>\n",
       "      <td>binary=False, lowercase = False, stop_words = \"english\"</td>\n",
       "      <td>0.738854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 3</td>\n",
       "      <td>Prelim_Reviews_Logistic Regression</td>\n",
       "      <td>binary=False, lowercase = False, stop_words = \"english\"</td>\n",
       "      <td>0.738854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Model 11</td>\n",
       "      <td>Stemtext_CV_Naive Bayes</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.687898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Model 12</td>\n",
       "      <td>Stemtext_CV_Logistic Regression</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.681529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 1</td>\n",
       "      <td>Prelim_Reviews_Decision Tree</td>\n",
       "      <td>binary=False, lowercase = False, stop_words = \"english\"</td>\n",
       "      <td>0.668790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 4</td>\n",
       "      <td>CleanText_CV_Decision Tree</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.656051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Model 7</td>\n",
       "      <td>CleanText_TfIdf_Decision Tree</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.617834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Model 10</td>\n",
       "      <td>Stemtext_CV_Decision Tree</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.541401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model NO                                 Name  \\\n",
       "4    Model 5             CleanText_CV_Naive Bayes   \n",
       "7    Model 8          CleanText_TfIdf_Naive Bayes   \n",
       "8    Model 9  CleanText_TfIdf_Logistic Regression   \n",
       "5    Model 6     CleanText_CV_Logistic Regression   \n",
       "1    Model 2           Prelim_Reviews_Naive Bayes   \n",
       "2    Model 3   Prelim_Reviews_Logistic Regression   \n",
       "10  Model 11              Stemtext_CV_Naive Bayes   \n",
       "11  Model 12      Stemtext_CV_Logistic Regression   \n",
       "0    Model 1         Prelim_Reviews_Decision Tree   \n",
       "3    Model 4           CleanText_CV_Decision Tree   \n",
       "6    Model 7        CleanText_TfIdf_Decision Tree   \n",
       "9   Model 10            Stemtext_CV_Decision Tree   \n",
       "\n",
       "                                                                                    Processing Parameters  \\\n",
       "4   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "7   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "8   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "5   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "1                                                 binary=False, lowercase = False, stop_words = \"english\"   \n",
       "2                                                 binary=False, lowercase = False, stop_words = \"english\"   \n",
       "10  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "11  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "0                                                 binary=False, lowercase = False, stop_words = \"english\"   \n",
       "3   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "6   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "9   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "\n",
       "    Model Accuracy  \n",
       "4         0.777070  \n",
       "7         0.770701  \n",
       "8         0.770701  \n",
       "5         0.764331  \n",
       "1         0.738854  \n",
       "2         0.738854  \n",
       "10        0.687898  \n",
       "11        0.681529  \n",
       "0         0.668790  \n",
       "3         0.656051  \n",
       "6         0.617834  \n",
       "9         0.541401  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[len(df)]=['Model 10','Stemtext_CV_Decision Tree',\n",
    "                 'lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)',\n",
    "                 DecisionTree_Stem_cv.score(X3_test,y3_test)]\n",
    "df.loc[len(df)]=['Model 11','Stemtext_CV_Naive Bayes',\n",
    "                 'lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)',\n",
    "                 NaiveBayes_Stem_cv.score(X3_test, y3_test)]\n",
    "df.loc[len(df)]=['Model 12','Stemtext_CV_Logistic Regression',\n",
    "                 'lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)',\n",
    "                 logit_Stem_cv.score(X3_test, y3_test)]\n",
    "result = df.sort_values(by= 'Model Accuracy',ascending=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus:  One extra point for every model run over the 12 you should have already. Maximum: 6 extra points.  \n",
    "Used the customized RL dictionary in prdicting the sentiment. Considere the sentiment of previous word from the corpus. Im planning to build a cutomized 'negate' and 'amplify' dictionary with all sentiment pairs from the corpus in this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hl_sent(inputstring):\n",
    "\n",
    "    poscount = 0\n",
    "    negcount = 0\n",
    "    i = 0\n",
    "\n",
    "\n",
    "    for word in inputstring.split():\n",
    "        if i > 0:\n",
    "            prev = inputstring.split().pop(i-1)\n",
    "        else:\n",
    "            prev =\"\"\n",
    "\n",
    "        if HLpos.count(word):\n",
    "            if negate.count(prev):\n",
    "                negcount += 1\n",
    "            elif amplify.count(prev):\n",
    "                poscount +=2\n",
    "            else: \n",
    "                poscount +=1\n",
    "        elif HLneg.count(word):\n",
    "            if negate.count(prev):\n",
    "                poscount += 1\n",
    "            elif amplify.count(prev):\n",
    "                negcount +=2\n",
    "            else:\n",
    "                negcount +=1\n",
    "        i+=1\n",
    "    \n",
    "    if poscount+negcount > 0:\n",
    "        t = float((poscount - negcount)/(poscount+negcount))\n",
    "        \n",
    "    else:\n",
    "        t = 0\n",
    "    \n",
    "    \n",
    "    if t > 0:\n",
    "        tone = \"Positive\"\n",
    "    elif t < 0:\n",
    "        tone = \"Negative\"\n",
    "    else:\n",
    "        tone = \"Neutral\"\n",
    "    \n",
    "    return tone\n",
    "\n",
    "\n",
    "#amplification and negation words from qdap\n",
    "negate = [\"scratches\",\"suspicious\",\"bad\",\"badly\",\"harsh\",\"loud\",\"frighteningly\",\"unacceptably\",\n",
    "          \"smelled\",\"fried\",\"guilty\",\"crazy\",\"ache\",\"sh*t\",\"die\",\"fell\",\"unhealthy\",\"snobby\",\n",
    "          \"painfully\",\"unreasonable\",\"ridiculously\",\"worst\",\"horrible\",\n",
    "        \"aint\", \"arent\",\"cant\", \"couldnt\" , \"didnt\" , \"doesnt\" ,\"dont\" ,\"hasnt\" , \"isnt\" ,\"mightnt\" , \"mustnt\" ,\n",
    "          \"neither\" ,\"never\", \"no\" ,\"nobody\" , \"nor\", \"not\" , \"shant\", \"shouldnt\", \"wasnt\" , \"werent\" ,\"wont\", \"wouldnt\"]\n",
    "amplify = [\"fairly\",\"pretty\",\"super\",\"unlimited\",\"work\",\"incredibly\",\"beautiful\",\"pleasant\",\n",
    "           \"tremendously\",\"decent\",\"generous\",\"lucky\",\"well\",\"nice\",\"free\",\"like\",\"promised\",\"awesome\",\n",
    "           \"sweet\",\"fresh\",\"tender\",\"thank\",\"hot\",\"heavenly\",\"conveniently\",\"wise\",\"good\",\"best\",\"perfectly\",\n",
    "            \"acute\" ,\"acutely\", \"certain\", \"certainly\" ,\"colossal\", \"colossally\",\"deep\" , \"deeply\" , \"definite\",\"definitely\" ,\n",
    "           \"enormous\",\"enormously\" , \"extreme\", \"extremely\" ,\"great\",\"greatly\" ,\"heavily\", \"heavy\", \"high\",\"highly\" ,\"huge\",\n",
    "           \"hugely\" , \"immense\", \"immensely\" ,\"incalculable\" ,\"incalculably\",\"massive\", \"massively\", \"more\",\"particular\" ,\n",
    "           \"particularly\",\"purpose\", \"purposely\", \"quite\" ,\"real\" ,\"really\",\"serious\", \"seriously\", \"severe\",\"severely\" ,\n",
    "           \"significant\" ,\"significantly\",\"sure\",\"surely\" , \"true\" ,\"truly\" ,\"vast\" , \"vastly\" , \"very\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviewdf['last'] = map(lambda x: hl_sent(x), reviewdf['cleantext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     count\n",
       "last           \n",
       "Negative     67\n",
       "Neutral      56\n",
       "Positive    268"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tab1 = pd.crosstab(index=reviewdf['last'],  # Make a crosstab\n",
    "                              columns=\"count\")      # Name the count column\n",
    "\n",
    "my_tab1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(391, 3150)\n",
      "(391, 3150)\n",
      "<type 'list'> 3150\n",
      "<type 'list'> 3150\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>food</th>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rlob</th>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shrimp</th>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count\n",
       "food      350\n",
       "rlob      327\n",
       "good      270\n",
       "shrimp    239\n",
       "time      191"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit and transform text\n",
    "cv_dm = cv1.fit_transform(reviewdf['cleantext'])\n",
    "tfidf_dm = tfidf1.fit_transform(reviewdf['cleantext'])\n",
    "\n",
    "# print matrix shape(s)\n",
    "print cv_dm.shape\n",
    "print tfidf_dm.shape\n",
    "names = cv1.get_feature_names()\n",
    "print type(names), len(names)\n",
    "\n",
    "count = np.sum(cv_dm.toarray(), axis = 0).tolist()\n",
    "print type(count), len(count)\n",
    "count_df = pd.DataFrame(count, index = names, columns = ['count'])\n",
    "\n",
    "count_df.sort_values(by= ['count'], ascending = False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "['Positive' 'Negative' 'Positive' 'Positive' 'Positive' 'Positive'\n",
      " 'Positive' 'Negative' 'Positive' 'Positive']\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "# data are X, labels are y\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X4 = cv_dm.toarray()  #remember this is the output from the vectorizer\n",
    "print type(X)\n",
    "\n",
    "\n",
    "y4 = reviewdf['last'].values #this is an array of labels\n",
    "print type(y)\n",
    "\n",
    "print y4[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234L, 3150L)\n",
      "(157L, 3150L)\n",
      "(234L,)\n",
      "(157L,)\n"
     ]
    }
   ],
   "source": [
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.4, random_state=50) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print X4_train.shape\n",
    "print X4_test.shape\n",
    "print y4_train.shape\n",
    "print y4_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.592356687898\n",
      "accuracy: 0.592356687898\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.23      0.39      0.29        23\n",
      "    Neutral       0.27      0.22      0.24        27\n",
      "   Positive       0.81      0.73      0.77       107\n",
      "\n",
      "avg / total       0.63      0.59      0.61       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# fit a CART_model to the data\n",
    "DecisionTree_Custom_Senti = DecisionTreeClassifier(random_state = 50)\n",
    "DecisionTree_Custom_Senti.fit(X4_train, y4_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y4_test\n",
    "clf1_predicted = DecisionTree_Custom_Senti.predict(X4_test)\n",
    "\n",
    "\n",
    "print DecisionTree_Custom_Senti.score(X4_test,y4_test)\n",
    "\n",
    "# summarize the fit of the CART_Model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.649681528662\n",
      "accuracy: 0.649681528662\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.25      0.13      0.17        23\n",
      "    Neutral       0.33      0.04      0.07        27\n",
      "   Positive       0.69      0.92      0.79       107\n",
      "\n",
      "avg / total       0.56      0.65      0.57       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive_Bayes_model to the data\n",
    "NaiveBayes_Custom_Senti = MultinomialNB()\n",
    "print NaiveBayes_Custom_Senti\n",
    "NaiveBayes_Custom_Senti.fit(X4_train, y4_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y4_test\n",
    "clf2_predicted = NaiveBayes_Custom_Senti.predict(X4_test)\n",
    "\n",
    "print NaiveBayes_Custom_Senti.score(X4_test, y4_test)\n",
    "\n",
    "# summarize the fit of the Naivebayes\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  15. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=50, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.656050955414\n",
      "accuracy: 0.656050955414\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.25      0.22      0.23        23\n",
      "    Neutral       0.20      0.04      0.06        27\n",
      "   Positive       0.73      0.91      0.81       107\n",
      "\n",
      "avg / total       0.57      0.66      0.60       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit a logistic regression model to the data\n",
    "logit_Custom_Senti = LogisticRegression(random_state = 50)\n",
    "print logit_Custom_Senti\n",
    "logit_Custom_Senti.fit(X4_train, y4_train)\n",
    "print logit_Custom_Senti.score(X4_test, y4_test)\n",
    "\n",
    "# make predictions\n",
    "clf3_expected = y4_test\n",
    "clf3_predicted = logit_Custom_Senti.predict(X4_test)\n",
    "\n",
    "# summarize the fit of the logit_pre_model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf3_expected, clf3_predicted)))\n",
    "print(metrics.classification_report(clf3_expected, clf3_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model NO</th>\n",
       "      <th>Name</th>\n",
       "      <th>Processing Parameters</th>\n",
       "      <th>Model Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model 5</td>\n",
       "      <td>CleanText_CV_Naive Bayes</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.777070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Model 8</td>\n",
       "      <td>CleanText_TfIdf_Naive Bayes</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.770701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Model 9</td>\n",
       "      <td>CleanText_TfIdf_Logistic Regression</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.770701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Model 6</td>\n",
       "      <td>CleanText_CV_Logistic Regression</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.764331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 2</td>\n",
       "      <td>Prelim_Reviews_Naive Bayes</td>\n",
       "      <td>binary=False, lowercase = False, stop_words = \"english\"</td>\n",
       "      <td>0.738854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 3</td>\n",
       "      <td>Prelim_Reviews_Logistic Regression</td>\n",
       "      <td>binary=False, lowercase = False, stop_words = \"english\"</td>\n",
       "      <td>0.738854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Model 11</td>\n",
       "      <td>Stemtext_CV_Naive Bayes</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.687898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Model 12</td>\n",
       "      <td>Stemtext_CV_Logistic Regression</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.681529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 1</td>\n",
       "      <td>Prelim_Reviews_Decision Tree</td>\n",
       "      <td>binary=False, lowercase = False, stop_words = \"english\"</td>\n",
       "      <td>0.668790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 4</td>\n",
       "      <td>CleanText_CV_Decision Tree</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.656051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Model 15</td>\n",
       "      <td>Custom_Senti_CV_Logistic Regression</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.656051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Model 14</td>\n",
       "      <td>Custom_Senti_CV_Naive Bayes</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.649682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Model 7</td>\n",
       "      <td>CleanText_TfIdf_Decision Tree</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.617834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Model 13</td>\n",
       "      <td>Custom_Senti_CV_Decision Tree</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.592357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Model 10</td>\n",
       "      <td>Stemtext_CV_Decision Tree</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.541401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model NO                                 Name  \\\n",
       "4    Model 5             CleanText_CV_Naive Bayes   \n",
       "7    Model 8          CleanText_TfIdf_Naive Bayes   \n",
       "8    Model 9  CleanText_TfIdf_Logistic Regression   \n",
       "5    Model 6     CleanText_CV_Logistic Regression   \n",
       "1    Model 2           Prelim_Reviews_Naive Bayes   \n",
       "2    Model 3   Prelim_Reviews_Logistic Regression   \n",
       "10  Model 11              Stemtext_CV_Naive Bayes   \n",
       "11  Model 12      Stemtext_CV_Logistic Regression   \n",
       "0    Model 1         Prelim_Reviews_Decision Tree   \n",
       "3    Model 4           CleanText_CV_Decision Tree   \n",
       "14  Model 15  Custom_Senti_CV_Logistic Regression   \n",
       "13  Model 14          Custom_Senti_CV_Naive Bayes   \n",
       "6    Model 7        CleanText_TfIdf_Decision Tree   \n",
       "12  Model 13        Custom_Senti_CV_Decision Tree   \n",
       "9   Model 10            Stemtext_CV_Decision Tree   \n",
       "\n",
       "                                                                                    Processing Parameters  \\\n",
       "4   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "7   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "8   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "5   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "1                                                 binary=False, lowercase = False, stop_words = \"english\"   \n",
       "2                                                 binary=False, lowercase = False, stop_words = \"english\"   \n",
       "10  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "11  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "0                                                 binary=False, lowercase = False, stop_words = \"english\"   \n",
       "3   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "14  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "13  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "6   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "12  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "9   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "\n",
       "    Model Accuracy  \n",
       "4         0.777070  \n",
       "7         0.770701  \n",
       "8         0.770701  \n",
       "5         0.764331  \n",
       "1         0.738854  \n",
       "2         0.738854  \n",
       "10        0.687898  \n",
       "11        0.681529  \n",
       "0         0.668790  \n",
       "3         0.656051  \n",
       "14        0.656051  \n",
       "13        0.649682  \n",
       "6         0.617834  \n",
       "12        0.592357  \n",
       "9         0.541401  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[len(df)]=['Model 13','Custom_Senti_CV_Decision Tree',\n",
    "                 'lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)',\n",
    "                 DecisionTree_Custom_Senti.score(X4_test,y4_test)]\n",
    "df.loc[len(df)]=['Model 14','Custom_Senti_CV_Naive Bayes',\n",
    "                 'lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)',\n",
    "                 NaiveBayes_Custom_Senti.score(X4_test, y4_test)]\n",
    "df.loc[len(df)]=['Model 15','Custom_Senti_CV_Logistic Regression',\n",
    "                 'lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)',\n",
    "                 logit_Custom_Senti.score(X4_test, y4_test)]\n",
    "result = df.sort_values(by= 'Model Accuracy',ascending=False)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n",
      "['Positive' 'Negative' 'Positive' 'Positive' 'Positive' 'Positive'\n",
      " 'Positive' 'Negative' 'Positive' 'Positive']\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "# data are X, labels are y\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X5 = tfidf_dm.toarray()  #remember this is the output from the vectorizer\n",
    "print type(X5)\n",
    "\n",
    "\n",
    "y5 = reviewdf['last'].values #this is an array of labels\n",
    "print type(y5)\n",
    "\n",
    "print y5[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234L, 3150L)\n",
      "(157L, 3150L)\n",
      "(234L,)\n",
      "(157L,)\n"
     ]
    }
   ],
   "source": [
    "X5_train, X5_test, y5_train, y5_test = train_test_split(X5, y5, test_size=0.4, random_state=50) #random_state is set seed\n",
    "\n",
    "# function creates 4 output structures - order matters\n",
    "print X5_train.shape\n",
    "print X5_test.shape\n",
    "print y5_train.shape\n",
    "print y5_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.573248407643\n",
      "accuracy: 0.573248407643\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.29      0.35      0.31        23\n",
      "    Neutral       0.19      0.15      0.17        27\n",
      "   Positive       0.72      0.73      0.73       107\n",
      "\n",
      "avg / total       0.57      0.57      0.57       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree Classifier\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# fit a CART_model to the data\n",
    "DecisionTree_Custom_Senti_TfIdf = DecisionTreeClassifier(random_state = 50)\n",
    "DecisionTree_Custom_Senti_TfIdf.fit(X5_train, y5_train)\n",
    "\n",
    "# make predictions\n",
    "clf1_expected = y5_test\n",
    "clf1_predicted = DecisionTree_Custom_Senti_TfIdf.predict(X5_test)\n",
    "\n",
    "\n",
    "print DecisionTree_Custom_Senti_TfIdf.score(X5_test,y5_test)\n",
    "\n",
    "# summarize the fit of the CART_Model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf1_expected, clf1_predicted)))\n",
    "print(metrics.classification_report(clf1_expected, clf1_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
      "0.68152866242\n",
      "accuracy: 0.68152866242\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.00      0.00      0.00        23\n",
      "    Neutral       0.00      0.00      0.00        27\n",
      "   Positive       0.68      1.00      0.81       107\n",
      "\n",
      "avg / total       0.46      0.68      0.55       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# fit a Naive_Bayes_model to the data\n",
    "NaiveBayes_Custom_Senti_TfIdf = MultinomialNB()\n",
    "print NaiveBayes_Custom_Senti_TfIdf\n",
    "NaiveBayes_Custom_Senti_TfIdf.fit(X5_train, y5_train)\n",
    "\n",
    "# make predictions\n",
    "clf2_expected = y5_test\n",
    "clf2_predicted = NaiveBayes_Custom_Senti_TfIdf.predict(X5_test)\n",
    "\n",
    "print NaiveBayes_Custom_Senti_TfIdf.score(X5_test, y5_test)\n",
    "\n",
    "# summarize the fit of the Naivebayes\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf2_expected, clf2_predicted)))\n",
    "print(metrics.classification_report(clf2_expected, clf2_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  18. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=50, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.68152866242\n",
      "accuracy: 0.68152866242\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.00      0.00      0.00        23\n",
      "    Neutral       0.00      0.00      0.00        27\n",
      "   Positive       0.68      1.00      0.81       107\n",
      "\n",
      "avg / total       0.46      0.68      0.55       157\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# fit a logistic regression model to the data\n",
    "logit_Custom_Senti_TfIdf = LogisticRegression(random_state = 50)\n",
    "print logit_Custom_Senti_TfIdf\n",
    "logit_Custom_Senti_TfIdf.fit(X5_train, y5_train)\n",
    "print logit_Custom_Senti_TfIdf.score(X5_test, y5_test)\n",
    "\n",
    "# make predictions\n",
    "clf3_expected = y5_test\n",
    "clf3_predicted = logit_Custom_Senti_TfIdf.predict(X5_test)\n",
    "\n",
    "# summarize the fit of the logit_pre_model\n",
    "print(\"accuracy: \" + str(metrics.accuracy_score(clf3_expected, clf3_predicted)))\n",
    "print(metrics.classification_report(clf3_expected, clf3_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model NO</th>\n",
       "      <th>Name</th>\n",
       "      <th>Processing Parameters</th>\n",
       "      <th>Model Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model 5</td>\n",
       "      <td>CleanText_CV_Naive Bayes</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.777070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Model 8</td>\n",
       "      <td>CleanText_TfIdf_Naive Bayes</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.770701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Model 9</td>\n",
       "      <td>CleanText_TfIdf_Logistic Regression</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.770701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Model 6</td>\n",
       "      <td>CleanText_CV_Logistic Regression</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.764331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 3</td>\n",
       "      <td>Prelim_Reviews_Logistic Regression</td>\n",
       "      <td>binary=False, lowercase = False, stop_words = \"english\"</td>\n",
       "      <td>0.738854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 2</td>\n",
       "      <td>Prelim_Reviews_Naive Bayes</td>\n",
       "      <td>binary=False, lowercase = False, stop_words = \"english\"</td>\n",
       "      <td>0.738854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Model 11</td>\n",
       "      <td>Stemtext_CV_Naive Bayes</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.687898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Model 18</td>\n",
       "      <td>Custom_Senti_TfIdf_Logistic Regression</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.681529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Model 17</td>\n",
       "      <td>Custom_Senti_TfIdf_Naive Bayes</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.681529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Model 12</td>\n",
       "      <td>Stemtext_CV_Logistic Regression</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.681529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 1</td>\n",
       "      <td>Prelim_Reviews_Decision Tree</td>\n",
       "      <td>binary=False, lowercase = False, stop_words = \"english\"</td>\n",
       "      <td>0.668790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Model 15</td>\n",
       "      <td>Custom_Senti_CV_Logistic Regression</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.656051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 4</td>\n",
       "      <td>CleanText_CV_Decision Tree</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.656051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Model 14</td>\n",
       "      <td>Custom_Senti_CV_Naive Bayes</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.649682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Model 7</td>\n",
       "      <td>CleanText_TfIdf_Decision Tree</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.617834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Model 13</td>\n",
       "      <td>Custom_Senti_CV_Decision Tree</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.592357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Model 16</td>\n",
       "      <td>Custom_Senti_TfIdf_Decision Tree</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.573248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Model 10</td>\n",
       "      <td>Stemtext_CV_Decision Tree</td>\n",
       "      <td>lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)</td>\n",
       "      <td>0.541401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model NO                                    Name  \\\n",
       "4    Model 5                CleanText_CV_Naive Bayes   \n",
       "7    Model 8             CleanText_TfIdf_Naive Bayes   \n",
       "8    Model 9     CleanText_TfIdf_Logistic Regression   \n",
       "5    Model 6        CleanText_CV_Logistic Regression   \n",
       "2    Model 3      Prelim_Reviews_Logistic Regression   \n",
       "1    Model 2              Prelim_Reviews_Naive Bayes   \n",
       "10  Model 11                 Stemtext_CV_Naive Bayes   \n",
       "17  Model 18  Custom_Senti_TfIdf_Logistic Regression   \n",
       "16  Model 17          Custom_Senti_TfIdf_Naive Bayes   \n",
       "11  Model 12         Stemtext_CV_Logistic Regression   \n",
       "0    Model 1            Prelim_Reviews_Decision Tree   \n",
       "14  Model 15     Custom_Senti_CV_Logistic Regression   \n",
       "3    Model 4              CleanText_CV_Decision Tree   \n",
       "13  Model 14             Custom_Senti_CV_Naive Bayes   \n",
       "6    Model 7           CleanText_TfIdf_Decision Tree   \n",
       "12  Model 13           Custom_Senti_CV_Decision Tree   \n",
       "15  Model 16        Custom_Senti_TfIdf_Decision Tree   \n",
       "9   Model 10               Stemtext_CV_Decision Tree   \n",
       "\n",
       "                                                                                    Processing Parameters  \\\n",
       "4   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "7   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "8   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "5   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "2                                                 binary=False, lowercase = False, stop_words = \"english\"   \n",
       "1                                                 binary=False, lowercase = False, stop_words = \"english\"   \n",
       "10  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "17  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "16  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "11  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "0                                                 binary=False, lowercase = False, stop_words = \"english\"   \n",
       "14  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "3   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "13  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "6   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "12  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "15  lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "9   lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)   \n",
       "\n",
       "    Model Accuracy  \n",
       "4         0.777070  \n",
       "7         0.770701  \n",
       "8         0.770701  \n",
       "5         0.764331  \n",
       "2         0.738854  \n",
       "1         0.738854  \n",
       "10        0.687898  \n",
       "17        0.681529  \n",
       "16        0.681529  \n",
       "11        0.681529  \n",
       "0         0.668790  \n",
       "14        0.656051  \n",
       "3         0.656051  \n",
       "13        0.649682  \n",
       "6         0.617834  \n",
       "12        0.592357  \n",
       "15        0.573248  \n",
       "9         0.541401  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[len(df)]=['Model 16','Custom_Senti_TfIdf_Decision Tree',\n",
    "                 'lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)',\n",
    "                 DecisionTree_Custom_Senti_TfIdf.score(X5_test,y5_test)]\n",
    "df.loc[len(df)]=['Model 17','Custom_Senti_TfIdf_Naive Bayes',\n",
    "                 'lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)',\n",
    "                 NaiveBayes_Custom_Senti_TfIdf.score(X5_test, y5_test)]\n",
    "df.loc[len(df)]=['Model 18','Custom_Senti_TfIdf_Logistic Regression',\n",
    "                 'lowercase=True, stop_words=my_stopwords, binary=False, max_df=0.95, min_df=0.003, ngram_range = (1,2)',\n",
    "                 logit_Custom_Senti_TfIdf.score(X5_test, y5_test)]\n",
    "result = df.sort_values(by= 'Model Accuracy',ascending=False)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
